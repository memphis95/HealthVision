# HealthVision

A  semi voice automated android application for the visually impaired. It contains 3 modules - Object Recognition, Disease Prediction and Health Monitor. Natural language processing and google voice assistant support is used for the voice assistant.

## Object Recognition
The model for object recognition consists of a 51-layer Residual Network (ResNet-51) as the backbone for the Feature Pyramid Network (FPN). All 4 convolutional blocks of Residual Network are used as base for FPN. It has multiple prediction and upsampling layers. It has lateral connection between the bottom-up pyramid and the top-down pyramid. It applies a 1x1 convolution layer before adding each layer. A 3x3 Conv layer is then applied and the result is used as a feature map by upper layers.

The pyramid of convolutional activation maps generated by FPN are passed to Region Proposal Network (RPN), eliminating the bottleneck of hardcoded algorithms like EdgeBoxes to get region proposals. RPN works as a first pass on the image and makes the binary decision if a region contains an object or not. It also outputs the confidence it has over the proposal. The proposed regions are sent to RoI Align layer which maps the proposed regions in image to the convolutional features maps of FPN. The feature maps of candidate regions are then used by classification, bounding box and mask predicting heads. 

The object recognition model was trained till 33 epochs with 1000 steps each epoch and 50 validation steps on the Microsoft Common Objects in Context dataset which contains 330K images, 1.5 million object instances and 91 object categories. Mean image subtraction was done to center align data. The system used for training was expanded by a NVidia 1050 Ti OC Graphic Card for higher processing capability.

## Disease Prediction
A disease-symptom dataset was crawled from websites like webmd.com and medicinenet.com. A graph database on Neo4j was implemented on the dataset to eliminate sparsity. The graph contains 149 disease nodes, 404 symptom nodes and 2126 “(:Symptom)-[:MAY_CAUSE]->(:Disease)” relationships i.e. unweighted directed edges from symptoms to corresponding disease. 

The Neo4j database was linked with Python using Py2neo driver and queried using Cypher Query Language (CQL). Symptoms spoken by the user were matched with corresponding diseases and returned. The Python code was hosted on a Flask server to send information back and forth between the android application and the database.

## Authors

* **Ankit Goel** - [memphis95](https://github.com/memphis95)
* **Shruti Sahu** - [whinyteen96](https://github.com/whinyteen96)
* **Pramit Gupta**



